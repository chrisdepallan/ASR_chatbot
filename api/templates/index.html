<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ASR Chatbot for UST</title>
    <link rel="stylesheet" href="{{ url_for('static', path='styles.css') }}">
    <script src="https://unpkg.com/wavesurfer.js@7/dist/wavesurfer.min.js"></script>
</head>
<body>
    <div class="chat-container">
        <div id="chatMessages"></div>
    </div>
    <div class="controls">
        <button id="recordButton">Record</button>
        <div id="waveform"></div>
        <button id="playButton">Play</button>
        <!-- <button id="transcribeButton">
            Transcribe
            <span class="arrow-icon"></span>
        </button> -->
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        const recordButton = document.getElementById('recordButton');
        const playButton = document.getElementById('playButton');
        let messageCounter = 0;
        
        // Initialize WaveSurfer
        const wavesurfer = WaveSurfer.create({
            container: '#waveform',
            waveColor: '#4F4A85',
            progressColor: '#383351',
            cursorColor: '#383351',
            barWidth: 3,
            barRadius: 3,
            responsive: true,
            height: 50,
            normalize: true,
        });

        recordButton.addEventListener('click', async () => {
            if (!mediaRecorder || mediaRecorder.state === 'inactive') {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);

                mediaRecorder.ondataavailable = event => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    audioChunks = [];
                    const audioUrl = URL.createObjectURL(audioBlob);
                    
                    // Load audio into wavesurfer
                    wavesurfer.loadBlob(audioBlob);
                    
                    recordButton.textContent = 'Record';
                    recordButton.classList.remove('recording');

                    await sendAudioToServer(audioBlob);
                };

                mediaRecorder.start();
                recordButton.textContent = 'Stop Recording';
                recordButton.classList.add('recording');
            } else {
                mediaRecorder.stop();
            }
        });

        playButton.addEventListener('click', () => {
            if (wavesurfer.isPlaying()) {
                wavesurfer.pause();
                playButton.textContent = 'Play';
            } else {
                wavesurfer.play();
                playButton.textContent = 'Pause';
            }
        });

        document.getElementById('transcribeButton').addEventListener('click', async () => {
            if (wavesurfer.backend.buffer) {
                // Convert AudioBuffer to Blob
                const audioData = wavesurfer.backend.buffer;
                const audioBlob = await audioBufferToWav(audioData);
                await sendAudioToServer(audioBlob);
            } else {
                alert('Please record or load audio first');
            }
        });

        // Helper function to convert AudioBuffer to WAV Blob
        function audioBufferToWav(buffer) {
            return new Promise(resolve => {
                const numberOfChannels = buffer.numberOfChannels;
                const sampleRate = buffer.sampleRate;
                const wavesurferBlob = wavesurfer.getDecodedData();
                resolve(new Blob([wavesurferBlob], { type: 'audio/wav' }));
            });
        }

        async function sendAudioToServer(audioBlob) {
            const formData = new FormData();
            formData.append('file', audioBlob, 'recording.wav');

            try {
                // First, get the transcription
                const transcriptionResponse = await fetch('/transcribe', {
                    method: 'POST',
                    body: formData
                });

                const transcriptionResult = await transcriptionResponse.json();
                
                // Display user's message
                const chatMessages = document.getElementById('chatMessages');
                const userMessageDiv = document.createElement('div');
                userMessageDiv.className = 'message user-message';
                userMessageDiv.textContent = transcriptionResult.transcription;
                chatMessages.appendChild(userMessageDiv);

                // Then, get the chat completion
                const chatResponse = await fetch('/chat', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        message: transcriptionResult.transcription
                    })
                });

                const chatResult = await chatResponse.json();
                
                // Display assistant's response with formatting
                const assistantMessageDiv = document.createElement('div');
                assistantMessageDiv.className = 'message assistant-message';
                
                // Create a container for the message and TTS button
                const messageContainer = document.createElement('div');
                messageContainer.className = 'message-container';
                
                // Add play button and audio element
                const audioId = `tts-audio-${messageCounter++}`;
                const playTTSButton = document.createElement('button');
                playTTSButton.className = 'play-tts-button';
                playTTSButton.innerHTML = 'ðŸ”Š'; // Speaker emoji
                playTTSButton.onclick = async () => {
                    try {
                        const ttsResponse = await fetch('/text-to-speech', {
                            method: 'POST',
                            headers: {
                                'Content-Type': 'application/json',
                            },
                            body: JSON.stringify({
                                text: chatResult.response
                            })
                        });
                        
                        if (ttsResponse.ok) {
                            const audioBlob = await ttsResponse.blob();
                            const audioUrl = URL.createObjectURL(audioBlob);
                            const audioElement = document.getElementById(audioId);
                            audioElement.src = audioUrl;
                            audioElement.play();
                        }
                    } catch (error) {
                        console.error('Error playing TTS:', error);
                        alert('Error playing audio');
                    }
                };

                const audioElement = document.createElement('audio');
                audioElement.id = audioId;
                
                // Convert markdown and format text as before
                const formattedText = chatResult.response
                    .replace(/```(\w+)?\n([\s\S]*?)```/g, (match, language, code) => {
                        return `<pre><code class="language-${language || ''}">${code.trim()}</code></pre>`;
                    })
                    .replace(/\n/g, '<br>');
                
                assistantMessageDiv.innerHTML = formattedText;
                
                // Assemble the message container
                messageContainer.appendChild(playTTSButton);
                messageContainer.appendChild(assistantMessageDiv);
                messageContainer.appendChild(audioElement);
                
                chatMessages.appendChild(messageContainer);

                // Scroll to bottom of chat
                chatMessages.scrollTop = chatMessages.scrollHeight;
            } catch (error) {
                console.error('Error:', error);
                print(error)
                alert('Error processing audio');
            }
        }
    </script>

    <style>
        .message-container {
            display: flex;
            align-items: flex-start;
            margin: 10px 0;
        }

        .play-tts-button {
            margin-right: 10px;
            padding: 5px 10px;
            background: #4F4A85;
            border: none;
            border-radius: 5px;
            color: white;
            cursor: pointer;
        }

        .play-tts-button:hover {
            background: #383351;
        }

        audio {
            display: none;
        }
    </style>
</body>
</html>